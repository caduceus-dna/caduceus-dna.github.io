<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Caducues Project Page">
  <meta property="og:title" content="Caduceus"/>
  <meta property="og:description" content="Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling"/>
  <meta property="og:url" content="https://kuleshov-group.github.io/caduceus.github.io/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/caduceus.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <title>Caduceus project page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <img src="static/images/favicon.ico" alt="Caduceus" style="width:50px;height:50px;">
            Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling
          </h1>
          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block">
              <a href="https://yair-schiff.github.io/" target="_blank">Yair Schiff<sup>1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://iandrover.github.io/" target="_blank">Chia-Hsiang Kao<sup>1</sup></a>,
            </span>
            <span class="author-block">
                <a href="https://skylion007.github.io/" target="_blank">Aaron Gokaslan<sup>1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://tridao.me/" target="_blank">Tri Dao<sup>2</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://twitter.com/_albertgu?lang=en" target="_blank">Albert Gu<sup>3</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.cornell.edu/~kuleshov/" target="_blank">Volodymyr Kuleshov<sup>1</sup></a>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup>
              Cornell&nbsp;
              <img src="static/images/cornell.png" alt="Cornell" style="float:right;width:30px;height:30px;">
            </span>
            <span class="author-block">
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>2</sup>
              Princeton&nbsp;
              <img src="static/images/princeton.svg" alt="Princeton" style="float:right;width:30px;height:30px;">
            </span>
            <span class="author-block">
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>3</sup>
              Carnegie Mellon
              <img src="static/images/cmu.jpeg" alt="Carnegie Mellon" style="float:right;width:30px;height:30px;">
              </span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- ArXiv abstract Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/kuleshov-group/caduceus" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>GitHub</span>
                </a>
              </span>
              <!-- HuggingFace link -->
              <span class="link-block">
                <a href="https://huggingface.co/collections/kuleshov-group/caducues-65dcb89b4f54e416ef61c350" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <p>&#129303;</p>
                  </span>
                  <span>HuggingFace</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Caduceus image -->
<section class="section hero">
  <div class="container is-max-desktop">
    <img src="static/images/caduceus.png" alt="Caduceus" style="width:300px;height:300px;">
  </div>
</section>

<!-- Introduction -->
<section class="section" id="Introduction">
  <div class="container is-max-desktop">
    <h2 class="title">DNA: The Next Frontier of Language Modeling?</h2>
    <div class="content is-medium">
      Large-scale sequence models have sparked rapid progress in machine learning, bringing about advances that extend beyond natural language processing into science, biology, and medicine.
      In proteomics, these models have enabled predicting protein structures from sequences, deciphering the functions and interactions of amino acids, and crafting new molecules.
      Building off these successes, DNA language models (LM) present an exciting frontier for sequence modeling.
      Understanding the fundamental material of biology holds the promise of accelerating the discovery of new drugs and providing new insights into the genetic basis of diseases.
    </div>
  </div>
</section>
<!-- End Introduction-->

<!--Intro Caduceus-->
<section class="section" id="Intro Caduceus">
  <div class="container is-max-desktop">
    <h2 class="title">Introducing Caduceus</h2>
    <div class="content is-medium">
      In our work, we introduce several architectural innovations specifically designed to tackle the unique challenges of modeling DNA sequences that build on the recently proposed Mamba module (<a href="https://arxiv.org/abs/2312.00752" target="_blank">Gu et al. (2023)</a>).
      We use these new blocks as the basis of Caduceus, a family of bidirectional long-range DNA sequence models that is the first language model to respect the reverse complement (RC) symmetry of the double-stranded structure of DNA.
      We further introduce pre-training and fine-tuning strategies that yield Caduceus foundation models for a wide range of predictive tasks in genomics.
      The Caduceus models consistently outperform previous state space model (SSM) based LMs of a similar size in terms of downstream performance.
      On many tasks, especially ones that require long-range modeling, Caduceus also outperforms 10x larger Transformer-based models.          
    </div>
    <div class="columns is-centered">
      <img src="static/images/caduceus_highlights.png" alt="Highlights of Caduceus"/>
    </div>
  </div>
</section>
<!-- End Intro Caduceus--->

<!-- DNA LM -->
<section class="section" id="DNA_LM">
  <div class="container is-max-desktop">
    <h2 class="title">What makes DNA LM unique?</h2>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <img src="static/images/why_dna/Slide1.png" alt="Challenges in DNA"/>
            <h2 class="subtitle has-text-centered">
              Challenges in DNA LM.
            </h2>
          </div>
          <div class="item">
            <img src="static/images/why_dna/Slide2.png" alt="DNA folding and coiling enables distal base pair interactions"/>
            <h2 class="subtitle has-text-centered">
              DNA folding and coiling enables distal base pair interactions.
            </h2>
          </div>
          <div class="item">
            <img src="static/images/why_dna/Slide3.png" alt="Upstream and downstream effects require bi-directional modeling"/>
            <h2 class="subtitle has-text-centered">
              Upstream and downstream effects require bi-directional modeling.
            </h2>
          </div>
          <div class="item">
            <img src="static/images/why_dna/Slide4.png" alt="Reverse complement strands carry equivalent information"/>
            <h2 class="subtitle has-text-centered">
              Reverse complement strands carry equivalent information.
            </h2>
          </div>
        </div>
      </div>
    </div>
    <br>
    <div class="content is-medium">
      <p>
        Modeling DNA introduces challenges that are distinct from those posed by natural language or proteins.
        First, many genomics tasks, such as predicting the effect of variants on gene expression, can entail <b>long-range interactions</b>, as nucleic acids even up to 1 million base pairs away from a given gene can have significant regulatory effects.
        Second, cellular phenotypes are often impacted by effects upstream and downstream in the genome, which requires sequence models to handle <b>bi-directional</b> context.
        Third, DNA consists of two strands that are <b>reverse complements</b> of each other and that carry the same information; modeling this property can significantly improve performance.
      </p>
    </div>
  </div>
</section>
<!-- End DNA LM -->

<!-- Blocks -->
<section class="section" id="Blocks">
  <div class="container is-max-desktop">
    <h2 class="title">Extending Mamba for DNA</h2>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <!-- Your video here -->
          <source src="static/videos/building_caduceus.mp4"
          type="video/mp4">
        </video>
      </div>
    </div>
    <br>
    <div class="content is-medium">
      <p>
        We introduce sequence modeling modules that can be applied across domains, but are specifically tailored to DNA.
        Specifically, we start by leveraging the recently proposed Mamba block (<a href="https://arxiv.org/abs/2312.00752" target="_blank">Gu et al. (2023)</a>) that uses a selective state space model for long-range sequence modeling, rivaling the performance of Transformer-based models.
        Using this module, we develop <b>BiMamba</b>, a parameter/memory-efficienct, bi-directional version of Mamba.
        BiMamba is implemented by running a Mamba module on both a sequence and its reverse, with in and out projection weights tied.
        We also introduce <b>MambaDNA</b>, a module that extends Mamba / BiMamba to support reverse complement equivariance.
      </p>
    </div>
  </div>
<!-- End Blocks-->

<!-- Caduceus -->
<section class="section" id="Caduceus">
  <div class="container is-max-desktop">
    <h2 class="title">Caduceus</h2>
    <img src="static/images/caduceus_arch.png" alt="Caduceus Architecture" style="float:left;padding-right:50px;height:375px;">
    <div class="content is-medium">
      <p>
        Using the sequence modeling blocks introduced above, we build <b>Caduceus</b>, a novel bi-directional DNA LM architecture that enforces RC equivariance.
        RC equivariance can be enforced in one of two ways.
        1) We use the MambaDNA block in conjunction with BiMamba as the backbone of a DNA LM.
        With RC equivariant embedding and LM head modules, this forms <b>Caduceus-PS</b> (parameter sharing), the first of its kind RC equivariant LM.
        2) Drawing inspiration from previous works that have investigated RC equivariant models (<a href="https://proceedings.mlr.press/v165/zhou22a.html" target="_blank">Zhou et al. (2022)</a>), we also propose <b>Caduceus-Ph</b> (<em>post hoc</em>), which does not perform RC equivariant language modeling, but is rather trained with RC data augmentation and then combines predictions for forward and RC sequences post hoc at downstream task inference time.
      </p>
    </div>
  </div>
  <br>
  <div class="columns is-centered">
    <div class="item">
      <img src="static/images/caducues_comparison.png" alt="Comparison to other DNA LMs"/>
      <h2 class="subtitle has-text-centered">
        Comparing to other DNA LMs.
      </h2>
    </div>
  </div>
</section>
<!-- End DNA LM -->

<!-- Experiments -->
<section class="section" id="Experiments">
  <div class="container is-max-desktop">
    <h2 class="title">Experiments</h2>
    <div class="content is-medium">
      We pre-trained models on the human reference genome.
      Similar to the preliminary results in <a href="https://arxiv.org/abs/2312.00752" target="_blank">Gu et al. (2023)</a>, we find that the Mamba module performs better than Hyena (<a href="https://arxiv.org/abs/2306.15794" target="_blank">Nguyen et al. (2023)</a>) in terms of next token prediction (see figure below on the left).
      This result lend support to our choice of Mamba as the inner building block of our models.
      Additionally, we find that the efficient parameter usage of BiMamba, which allows us to train deeper models for comparable parameter counts relative to not using weight tying, leads to better pre-train performance (see the middle figure below). 
      Finally, we find that RC equivariant LM leads to better masked language modeling pre-training loss (see figure below on the right).
      These results are significant because performance on the MLM task has grounding in the biology of downstream tasks, such as variant effect prediction.
    </div>
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="item">
          <img src="static/images/experiments/pretrain.png" alt="Ablating the effect of RC equivariance on pre-training"/>
          <!-- <img src="static/images/experiments/mamba_pretraining.png" alt="Ablating the effect of RC equivariance on pre-training" style="float:left;height:300px;"/> -->
          <!-- <img src="static/images/experiments/rc_pretraining.png" alt="Ablating the effect of RC equivariance on pre-training" style="height:500px;"/> -->
        </div>
      </div>
    </div>
    <br><br>
    <div class="content is-medium">
      We evaluate models on a range of biologically relevant downstream tasks, as described below.
    </div>
    <h2 class="subtitle"> Nucleotide Transformer Benchmark</h2>
    <div class="content is-medium">
      <p>
        One set of benchmarks comes from the suite of tasks introduced in Nucleotide Transformer (<a href="https://www.biorxiv.org/content/10.1101/2023.01.11.523679v1" target="_blank">Dalla-Torre et al. (2023)</a>).
        We find that Caduceus-Ph performs competitively, even beating attention-based methods with orders of magnitude more parameters on 8 of 18 prediction tasks.
        Caduceus models outperform a similarly sized HyenaDNA (<a href="https://arxiv.org/abs/2306.15794" target="_blank">Nguyen et al. (2023)</a>) model on almost all the histone marker and regulatory annotation tasks, while HyenaDNA performs better on splice site annotation.
      </p>
    </div>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <img src="static/images/experiments/nt_benchmark.png" alt="Nucleotide Transformer Benchmark" style="width:100%;height:100%;">
      </div>
    </div>
  <h2 class="subtitle"> Predicting the Effect of Variants on Gene Expression</h2>
    <div class="content is-medium">
      <p>
        We explore the implications of long-range contexts on the task of predicting the effect of SNPs on gene expression.
        There is biological evidence to suggest this task indeed entails long-range interactions.
        Additionally it aligns well to LM pre-training objectives, which enable models to implicitly learn to recognize the effects of evolutionary pressure (e.g., conservation, co-evolution).
        The dataset used in this task is derived from the Enformer paper (<a href="https://www.nature.com/articles/s41592-021-01252-x" target="_blank">Avsec et al. (2021)</a>)  and presented in <a href="https://llms4science-community.github.io/papers/LLMs4Bio24_paper_12.pdf" target="_blank">Trop et al. (2024)</a>.
        From each model, we extract embeddings centered around the SNP location.
        We stratify the data by distance of the SNP to nearest Transcription Start Site (TSS).
        For each bucket, we sample 5,000 training points and fit an SVM classifier with an RBF kernel to predict VEP annotations.
        We report test set AUCROC mean and max/min ranges for classifiers fit on 5 random training subsets.
        We compare Caduceus to HyenaDNA and Nucleotide Transformer.
        As shown in the figure below the Caduceus models consistently outperform HyenaDNA, and Caduceus-PS exceeds the performance of the Nucleotide Transformer v2 (with 500M parameters) by a large margin, especially as  distance to the nearest TSS grows.
      </p>
    </div>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <img src="static/images/experiments/vep.png" alt="Variant Effect Prediction" style="width:100%;height:100%;">
      </div>
    </div>
  </div>
  <!-- End Experiments-->

<!-- Conclusion -->
<section class="section" id="Conclusion">
  <div class="container is-max-desktop">
    <h2 class="title">Conclusion</h2>
    <div class="content is-medium">
      <p>
        In this work, we introduced architectural innovations to the Mamba module: enabling bi-directional and RC equivariant sequence modeling.
        We also propose a new DNA foundation model, Caduceus, and demonstrate its ability to outperform comparably sized uni-directional Hyena-based models and Transformer-based models orders of magnitude larger in size on a range of biologically relevant tasks, most notably predicting the effect of genetic mutations on gene expression.
      </p>
    </div>
  </div>
<!-- End Experiments-->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content is-medium">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>
